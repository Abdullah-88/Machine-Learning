# -*- coding: utf-8 -*-
"""Lecture12_Clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tl7MjnrRldorcgTlbJ1kxN8rm_hlPY0N
"""

# K-Means clustering

from sklearn import datasets
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.cluster import KMeans

iris = datasets.load_iris()
X = iris.data[:, :2]
y = iris.target

X.shape

plt.scatter(X[:,0], X[:,1], c=y, cmap='gist_rainbow')
plt.xlabel('Spea1 Length', fontsize=18)
plt.ylabel('Sepal Width', fontsize=18)

maximum_clusters = 10
for trial in range(1,maximum_clusters+1):
  km = KMeans(n_clusters = trial)
  km.fit(X)
  # output centres
  centers = km.cluster_centers_
  print(km.labels_)
  print(centers)
  # plot clusters against annual income and spending score
  plt.title("Trial with {} Clusters".format(trial))
  #plt.figure(figsize=(10, 7))  
  plt.scatter(X[:,0], X[:,1], c=km.labels_)
  plt.show()

km = KMeans(n_clusters = 3)
km.fit(X)

centers = km.cluster_centers_
print(centers)

# Plot the identified clusters and compare with the answers
new_labels = km.labels_
fig, axes = plt.subplots(1, 2, figsize=(16,8))
axes[0].scatter(X[:, 0], X[:, 1], c=y, cmap='gist_rainbow',
edgecolor='k', s=150)
axes[1].scatter(X[:, 0], X[:, 1], c=new_labels, cmap='jet',
edgecolor='k', s=150)
axes[0].set_xlabel('Sepal length', fontsize=18)
axes[0].set_ylabel('Sepal width', fontsize=18)
axes[1].set_xlabel('Sepal length', fontsize=18)
axes[1].set_ylabel('Sepal width', fontsize=18)
axes[0].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20)
axes[1].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20)
axes[0].set_title('Actual', fontsize=18)
axes[1].set_title('Predicted', fontsize=18)

# Hirarchical Agglomerative Clustering

from sklearn.cluster import AgglomerativeClustering
agglo = AgglomerativeClustering(n_clusters=3,linkage="ward",affinity="euclidean")
agglo.fit(X)

# Plot the identified clusters and compare with the answers
new_labels = agglo.labels_
fig, axes = plt.subplots(1, 2, figsize=(16,8))
axes[0].scatter(X[:, 0], X[:, 1], c=y, cmap='gist_rainbow',
edgecolor='k', s=150)
axes[1].scatter(X[:, 0], X[:, 1], c=new_labels, cmap='jet',
edgecolor='k', s=150)
axes[0].set_xlabel('Sepal length', fontsize=18)
axes[0].set_ylabel('Sepal width', fontsize=18)
axes[1].set_xlabel('Sepal length', fontsize=18)
axes[1].set_ylabel('Sepal width', fontsize=18)
axes[0].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20)
axes[1].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20)
axes[0].set_title('Actual', fontsize=18)
axes[1].set_title('Predicted', fontsize=18)

# The Dendrogram method
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

data = pd.read_csv('Week12_data_Wholesale customers.csv')
data.head()

from sklearn.preprocessing import normalize

data_norm = normalize(data)
data_norm = pd.DataFrame(data_norm, columns=data.columns)
data_norm.head()

import scipy.cluster.hierarchy as shc
plt.figure(figsize=(10, 7))  
plt.title("Dendrograms")  
dend = shc.dendrogram(shc.linkage(data_norm, method='ward'))

plt.figure(figsize=(10, 7))  
plt.title("Dendrograms")  
dend = shc.dendrogram(shc.linkage(data_norm, method='ward'))
plt.axhline(y=6, color='r', linestyle='--')

from sklearn.cluster import AgglomerativeClustering
cluster = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')  
cluster.fit_predict(data_norm)

plt.figure(figsize=(10, 7))  
plt.scatter(data_norm['Milk'], data_norm['Grocery'], c=cluster.labels_)